{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ty7Zz2_04c3"
      },
      "source": [
        "Add a figure of methodology framework"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSjtDYkkXDXw"
      },
      "source": [
        "# SETUP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvqO31oL_T7c"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "R_5hjYjdCc-r"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "import io\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "from typing import Optional\n",
        "\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "import torch\n",
        "from bs4 import BeautifulSoup\n",
        "from dotenv import load_dotenv\n",
        "from googleapiclient.discovery import build\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from openpyxl import load_workbook\n",
        "from openpyxl.drawing.spreadsheet_drawing import OneCellAnchor, TwoCellAnchor\n",
        "from PIL import Image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "jyjvDjvIOPtl"
      },
      "outputs": [],
      "source": [
        "# get .env keys\n",
        "load_dotenv()\n",
        "API_KEY = os.getenv(\"API_KEY\")\n",
        "CSE_ID = os.getenv(\"CSE_ID\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUGBqya9_ZsS"
      },
      "source": [
        "## Ollama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "DQ-ckmscXtN0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ollama served at http://localhost:11434/\n"
          ]
        }
      ],
      "source": [
        "# check for Ollama instance\n",
        "for i in range(30):\n",
        "    try:\n",
        "        r = requests.get(\"http://localhost:11434/api/tags\", timeout=1)\n",
        "        if r.status_code == 200:\n",
        "            print(\"Ollama served at http://localhost:11434/\")\n",
        "            break\n",
        "    except Exception:\n",
        "        time.sleep(1)\n",
        "else:\n",
        "    raise RuntimeError(\"Ollama failed to start.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "collapsed": true,
        "id": "GwITGgkkYgx_"
      },
      "outputs": [],
      "source": [
        "# pull models from https://ollama.com/library\n",
        "# ! ollama pull qwen3-embedding:0.6b\n",
        "# ! ollama pull qwen3:0.6b\n",
        "# ! ollama pull qwen2.5vl:3b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwDXmXTgF2op"
      },
      "source": [
        "# CLAIM PROCESSING\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "collapsed": true,
        "id": "W_rEm6En59Xq"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# download nltk resources\n",
        "NLTK_DATA_DIR = os.path.join(os.getcwd(), \"cache/nltk_data\")\n",
        "os.makedirs(NLTK_DATA_DIR, exist_ok=True)\n",
        "nltk.data.path.append(NLTK_DATA_DIR)\n",
        "nltk.download(\"punkt\", quiet=True, download_dir=NLTK_DATA_DIR)\n",
        "nltk.download(\"punkt_tab\", quiet=True, download_dir=NLTK_DATA_DIR)\n",
        "nltk.download(\"stopwords\", quiet=True, download_dir=NLTK_DATA_DIR)\n",
        "nltk.download(\"wordnet\", quiet=True, download_dir=NLTK_DATA_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WJ0Of8zHEig"
      },
      "source": [
        "## Text Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "YkKL2Ly0E18u"
      },
      "outputs": [],
      "source": [
        "def make_query(claim: str) -> str:\n",
        "    \"\"\"\n",
        "    Apply basic preprocessing to convert a claim into a keyword-based search query.\n",
        "    \"\"\"\n",
        "    print(f\"Generating query from text: '{claim}'\")\n",
        "\n",
        "    # normalization\n",
        "    text = claim.lower()\n",
        "    text = re.sub(r\"[^a-z0-9\\s]\", \" \", text)\n",
        "\n",
        "    # tokenization\n",
        "    tokens = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    tokens = [t for t in tokens if t not in stop_words and len(t) > 2]\n",
        "\n",
        "    # lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmas = [lemmatizer.lemmatize(t) for t in tokens]\n",
        "    lemmas = list(dict.fromkeys(lemmas))\n",
        "\n",
        "    query = \" \".join(lemmas)\n",
        "    return query"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1itV65OHMyP"
      },
      "source": [
        "## Image Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "cfcj4NUviVC7"
      },
      "outputs": [],
      "source": [
        "def caption(image_path: str, text_claim: Optional[str], model: str):\n",
        "    \"\"\"\n",
        "    Generate descriptive text claims from an image claim. If text claim already exists, add more context from image.\n",
        "    \"\"\"\n",
        "    print(f\"Generating query from image: '{image_path}'\")\n",
        "\n",
        "    with open(image_path, \"rb\") as f:\n",
        "        image_b64 = base64.b64encode(f.read()).decode(\"utf-8\")\n",
        "\n",
        "    if text_claim.strip():\n",
        "        prompt = f\"\"\"\n",
        "        From the provided image, add more context to the text statement for fact-checking.\n",
        "        Keep the statement concise and optimal as a search query.\n",
        "        Respond only with the new statement as plain text.\n",
        "\n",
        "        Statement: {text_claim}\n",
        "        \"\"\"\n",
        "    else:\n",
        "        prompt = f\"\"\"\n",
        "        From the provided image, extract the statements to be fact-checked.\n",
        "        Keep the statement concise and optimal as a search query.\n",
        "        Respond only with the statement as plain text.\n",
        "        \"\"\"\n",
        "\n",
        "    response = requests.post(\n",
        "        \"http://localhost:11434/api/generate\",\n",
        "        json={\"model\": model, \"prompt\": prompt, \"images\": [image_b64], \"stream\": False},\n",
        "    )\n",
        "\n",
        "    return response.json().get(\"response\", \"\").strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKQ2K_VLRtq2"
      },
      "source": [
        "# RETRIEVAL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "uSGyVJniRJcu"
      },
      "outputs": [],
      "source": [
        "def search(query: str, num_results: int) -> list[str]:\n",
        "    \"\"\"\n",
        "    Retrieve URLs using Google Custom Search API.\n",
        "    Return a list of string URLs.\n",
        "    \"\"\"\n",
        "    print(f\"Searching with query: '{query}'\")\n",
        "\n",
        "    service = build(\"customsearch\", \"v1\", developerKey=API_KEY)\n",
        "    res = service.cse().list(q=query, cx=CSE_ID, num=num_results).execute()\n",
        "    urls = []\n",
        "    for item in res.get(\"items\", []):\n",
        "        urls.append(item[\"link\"])\n",
        "\n",
        "    print(f\"Found {len(urls)} URLs\")\n",
        "    return urls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "QnHS3Ig_ClGz"
      },
      "outputs": [],
      "source": [
        "def fetch_text(url: str) -> str:\n",
        "    \"\"\"\n",
        "    Fetch article text from a given URL.\n",
        "    Return the string body text from the HTML content.\n",
        "    \"\"\"\n",
        "    print(f\"Fetching article with URL: {url}\")\n",
        "    try:\n",
        "        r = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"}, timeout=10)\n",
        "        if r.status_code != 200:\n",
        "            print(f\"    Failed to fetch: ({r.status_code})\")\n",
        "            return \"\"\n",
        "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
        "        ps = soup.select(\"article p, .entry-content p, p\")\n",
        "        text = \" \".join(p.get_text(strip=True) for p in ps)\n",
        "        return text if text.strip() else \"\"\n",
        "    except Exception as e:\n",
        "        print(f\"    Error while fetching: {e}\")\n",
        "        return \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_jgtXiNRHDM"
      },
      "outputs": [],
      "source": [
        "def retrieve(urls: list[str]) -> list[tuple[str, str]]:\n",
        "    \"\"\"\n",
        "    Retrieve documents from search results based on a query.\n",
        "    Return list of (url, text) tuples.\n",
        "    \"\"\"\n",
        "    documents = []\n",
        "    for url in urls:\n",
        "        document_text = fetch_text(url)\n",
        "        if document_text.strip():\n",
        "            documents.append((url, document_text))\n",
        "\n",
        "    print(f\"Successfully retrieved {len(documents)} documents.\\n\")\n",
        "    return documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohUIp22PTyzM"
      },
      "source": [
        "# EMBEDDING AND RERANKING\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTpFxhjkHUux"
      },
      "source": [
        "## Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "UiYnGkNxxiIq"
      },
      "outputs": [],
      "source": [
        "def embed(\n",
        "    query: str, documents: list[tuple[str, str]], model_name: str\n",
        ") -> tuple[torch.Tensor, torch.Tensor, list[str], list[str]]:\n",
        "    \"\"\"\n",
        "    Generate embeddings for a query and a list of documents using Ollama.\n",
        "    Return query_embeddings, document_embeddings, urls, document_texts\n",
        "    \"\"\"\n",
        "    if not documents:\n",
        "        raise RuntimeError(\"No documents provided for embedding.\")\n",
        "\n",
        "    print(f\"Embedding {len(documents)} documents...\")\n",
        "\n",
        "    # helper function\n",
        "    def ollama_embed(text: str):\n",
        "        try:\n",
        "            res = requests.post(\n",
        "                \"http://localhost:11434/api/embeddings\",\n",
        "                json={\"model\": model_name, \"prompt\": text},\n",
        "            )\n",
        "            data = res.json()\n",
        "            return data.get(\"embedding\", [])\n",
        "        except Exception as e:\n",
        "            print(f\"    Error getting embedding: {e}\")\n",
        "            return []\n",
        "\n",
        "    # query embedding\n",
        "    print(\"Generating query embedding...\")\n",
        "    query_vec = ollama_embed(query)\n",
        "    if not query_vec:\n",
        "        raise RuntimeError(\"Query embedding failed.\")\n",
        "\n",
        "    expected_dim = len(query_vec)\n",
        "    print(f\"Query embedding dimension: {expected_dim}\")\n",
        "\n",
        "    # document embeddings\n",
        "    doc_vecs = []\n",
        "    valid_urls = []\n",
        "    valid_texts = []\n",
        "\n",
        "    for url, text in documents:\n",
        "        print(f\"Embedding document with URL: {url}\")\n",
        "        vec = ollama_embed(text)\n",
        "        if not vec:\n",
        "            print(f\"    WARNING: Empty embedding for document. Skipping\")\n",
        "            continue\n",
        "        if len(vec) != expected_dim:\n",
        "            print(f\"    WARNING: Embedding dimension mismatch ({len(vec)} vs {expected_dim}). Skipping.\")\n",
        "            continue\n",
        "        doc_vecs.append(vec)\n",
        "        valid_urls.append(url)\n",
        "        valid_texts.append(text)\n",
        "\n",
        "    if not doc_vecs:\n",
        "        raise RuntimeError(\"No valid document embeddings generated.\")\n",
        "    print(f\"Successfully embedded {len(doc_vecs)} documents.\\n\")\n",
        "\n",
        "    query_embeddings = torch.tensor(np.array([query_vec]), dtype=torch.float32)\n",
        "    document_embeddings = torch.tensor(np.array(doc_vecs), dtype=torch.float32)\n",
        "\n",
        "    return query_embeddings, document_embeddings, valid_urls, valid_texts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liasyPJbHXvk"
      },
      "source": [
        "## Reranking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "cGiFoI9uTvoU"
      },
      "outputs": [],
      "source": [
        "def rerank(\n",
        "    query_embeddings: Optional[torch.Tensor],\n",
        "    document_embeddings: Optional[torch.Tensor],\n",
        "    urls: list[str],\n",
        "    document_texts: list[str],\n",
        "    top_k: int = 3,\n",
        ") -> list[tuple[str, str, float]]:\n",
        "    \"\"\"\n",
        "    Rerank precomputed embeddings using cosine similarity.\n",
        "    Return a list of (url, text, score) tuples sorted by relevance score.\n",
        "    \"\"\"\n",
        "    if query_embeddings is None or document_embeddings is None:\n",
        "        raise RuntimeError(\"Query or document embeddings not found.\")\n",
        "    print(f\"Reranking {len(document_texts)} documents...\")\n",
        "\n",
        "    query_norm = query_embeddings / query_embeddings.norm(dim=1, keepdim=True)\n",
        "    doc_norms = document_embeddings / document_embeddings.norm(dim=1, keepdim=True)\n",
        "\n",
        "    scores = torch.mm(query_norm, doc_norms.T)[0].cpu().numpy()\n",
        "\n",
        "    ranked = list(zip(urls, document_texts, scores))\n",
        "    ranked.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "    return ranked[:top_k]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FgRCDHzbNYi"
      },
      "source": [
        "# PREMISE GENERATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "fOvQJObrbQTT"
      },
      "outputs": [],
      "source": [
        "def generate_premise(claim: str, documents: list[str], model: str):\n",
        "    \"\"\"\n",
        "    Summarize the evidence retrieved for a claim into a short premise.\n",
        "    \"\"\"\n",
        "    joined_documents = \"\\n\".join([f\"- {document}\" for document in documents])\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Claim: \"{claim}\"\n",
        "\n",
        "    Documents:\n",
        "    {joined_documents}\n",
        "\n",
        "    From the fact-checking articles, extract the basis that supports or refutes the claim.\n",
        "    Ignore documents that neither support nor refute the claim.\n",
        "    Only give the evidence as plain text.\n",
        "    \"\"\"\n",
        "\n",
        "    response = requests.post(\n",
        "        \"http://localhost:11434/api/generate\",\n",
        "        json={\"model\": model, \"prompt\": prompt, \"stream\": False},\n",
        "    )\n",
        "\n",
        "    return response.json().get(\"response\", \"\").strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NJYZPteT1ZC"
      },
      "source": [
        "# PIPELINE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "h66pwXz-S8uw"
      },
      "outputs": [],
      "source": [
        "def pipeline(text_claim: str, image_path: Optional[str]) -> list[tuple[str, str, float]]:\n",
        "    \"\"\"\n",
        "    Complete IR pipeline: retrieve, rerank, and return top documents.\n",
        "    Return a list of (url, text, score) tuples for top_k most relevant documents.\n",
        "    \"\"\"\n",
        "    # parameters\n",
        "    ollama_emb_name = \"qwen3-embedding:0.6b\"\n",
        "    ollama_llm_name = \"qwen3:0.6b\"\n",
        "    ollama_vlm_name = \"qwen2.5vl:3b\"\n",
        "    num_results = 5\n",
        "    top_k = 1\n",
        "\n",
        "    # preprocessing\n",
        "    if image_path:\n",
        "        image_claim = caption(image_path, text_claim, ollama_vlm_name)\n",
        "        query = make_query(image_claim)\n",
        "        if not text_claim.strip():\n",
        "            text_claim = image_claim # if image only, use response as text claim\n",
        "    else:\n",
        "        query = make_query(text_claim)\n",
        "\n",
        "    # retrieval\n",
        "    urls = search(query, num_results)\n",
        "\n",
        "    return urls\n",
        "\n",
        "    documents = retrieve(urls)\n",
        "    if not documents:\n",
        "        premise = \"No documents related to the claim were found.\"\n",
        "        return premise\n",
        "\n",
        "    # embedding\n",
        "    claim_embeddings, document_embeddings, urls, document_texts = embed(text_claim, retrieved_documents, ollama_emb_name)\n",
        "\n",
        "    # reranking\n",
        "    best_docs = rerank(claim_embeddings, document_embeddings, urls, document_texts, top_k)\n",
        "    for url, text, score in best_docs:\n",
        "        print(f\"{url}\\nScore: {score:.3f}\\nText: {text[101:301]}\\n\")\n",
        "\n",
        "    # premise generation\n",
        "    premise = generate_premise(text_claim, best_docs, ollama_llm_name)\n",
        "\n",
        "    return premise, best_docs[0][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOKzLsGI_oaw"
      },
      "source": [
        "## Test Claim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXHlqJ2pSl3Y"
      },
      "source": [
        "**Notes**\n",
        "\n",
        "*   Claims in English are processed better than claims in Filipino. Seek more robust (maybe multilingual-LLM-based) solutions as a possible optimization step.\n",
        "\n",
        "*   With limited testing, decomposing claims into multiple subclaims have yet to prove useful. It multiplies the processing time (2-5x), but Google SEO seems to be powerful enough with just one query.\n",
        "   \n",
        "*   Better reranking scores (~20%) when using multilingual embedding models for claims/documents in Filipino. Multilingual models allow for shared embedding spaces across languages, e.g. mixed English/Filipino documents."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKaD4O751b-D"
      },
      "source": [
        "For image input: Show the image, side-by-side with the output text\n",
        "\n",
        "For text input: print excerpts/snippets of retrieved documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing claim...\n",
            "\n",
            "Generating query from image: './datasets/documents/1.png'\n",
            "Generating query from text: 'Vico Sotto and Atasha Mulach pregnancy confirmed'\n",
            "Searching with query: 'vico sotto atasha mulach pregnancy confirmed'\n",
            "Found 5 URLs\n",
            "\n",
            "Finished processing!\n",
            "\n",
            "MATCH: https://www.factrakers.org/post/vico-sotto-atasha-muhlach-pregnancy-hoax-resurfaces\n"
          ]
        }
      ],
      "source": [
        "claim = \"Vico Sotto and Atasha Mulach pregnancy\"\n",
        "image_path = \"./datasets/documents/1.png\"\n",
        "link = \"https://www.factrakers.org/post/vico-sotto-atasha-muhlach-pregnancy-hoax-resurfaces\"\n",
        "\n",
        "print(\"\\nProcessing claim...\\n\")\n",
        "urls = pipeline(claim, image_path)\n",
        "print(\"\\nFinished processing!\\n\")\n",
        "\n",
        "if link in urls:\n",
        "    print(f\"MATCH: {link}\")\n",
        "else:\n",
        "    print(f\"NO MATCH: {urls}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_df(path, output_dir=\"datasets/extracted_images\"):\n",
        "    wb = load_workbook(path)\n",
        "    ws = wb.active\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # load all text data\n",
        "    data = []\n",
        "    headers = [cell.value for cell in ws[1]]\n",
        "    for row in ws.iter_rows(min_row=2, values_only=True):\n",
        "        data.append(list(row))\n",
        "    df = pd.DataFrame(data, columns=headers)\n",
        "\n",
        "    # column for image paths\n",
        "    df[\"Image Path\"] = None\n",
        "\n",
        "    # extract images and map them to row numbers\n",
        "    for idx, img in enumerate(ws._images):\n",
        "        anchor = img.anchor\n",
        "        if isinstance(anchor, str):\n",
        "            ref = anchor\n",
        "        elif hasattr(anchor, \"_from\"):\n",
        "            ref = f\"{chr(anchor._from.col + 65)}{anchor._from.row + 1}\"\n",
        "        else:\n",
        "            ref = None\n",
        "\n",
        "        img_bytes = io.BytesIO(img._data())\n",
        "        pil_img = Image.open(img_bytes)\n",
        "\n",
        "        filename = f\"img_{idx+1}_{ref or 'unknown'}.png\"\n",
        "        filepath = os.path.join(output_dir, filename)\n",
        "        pil_img.save(filepath)\n",
        "\n",
        "        # match image to row\n",
        "        if ref:\n",
        "            try:\n",
        "                row_num = int(''.join(filter(str.isdigit, ref)))\n",
        "                df.loc[row_num - 2, \"Image Path\"] = filepath\n",
        "            except ValueError:\n",
        "                pass\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_dataset(pipeline, df: pd.DataFrame):\n",
        "    matches = []\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        claim = row.get(\"Hypothesis/Claims\")\n",
        "        image_path = row.get(\"Image Path\")\n",
        "        link = row.get(\"Link\")\n",
        "\n",
        "        if not isinstance(claim, str) or not claim.strip():\n",
        "            matches.append(None)\n",
        "            continue\n",
        "\n",
        "        if not (isinstance(image_path, str) and os.path.exists(image_path)):\n",
        "            image_path = None\n",
        "\n",
        "        try:\n",
        "            url = pipeline(claim, image_path)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing row: {e}\")\n",
        "            url = None\n",
        "\n",
        "        match = link in url     \n",
        "        if match:\n",
        "            print(f\"MATCH: {link}\\n--- --- --- --- ---\\n\")\n",
        "        else:\n",
        "            print(f\"NO MATCH:\\nOriginal: {link}\\nRetrieved: {url}\\n--- --- --- --- ---\\n\")\n",
        "        matches.append(match)\n",
        "    \n",
        "    df[\"Match\"] = matches    \n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating query from image: 'datasets/extracted_images\\img_1_H2.png'\n",
            "Generating query from text: 'A post on the Facebook page Guerrero Noticias features a series of pictures of underwater wreckage, which is allegedly related to the missing deep-sea submersible Titan.'\n",
            "Searching with query: 'post facebook page guerrero noticias feature series picture underwater wreckage allegedly related missing deep sea submersible titan'\n",
            "Found 1 URLs\n",
            "MATCH: https://www.rappler.com/newsbreak/fact-check/facebook-post-shows-no-real-images-titan-submersible-wreckage/\n",
            "--- --- --- --- ---\n",
            "\n",
            "Generating query from text: 'As of writing (Jun 23, 2023), no images of the Titan’s wreckage and debris have been released to the media.'\n",
            "Searching with query: 'writing jun 2023 image titan wreckage debris released medium'\n",
            "Found 1 URLs\n",
            "MATCH: https://www.rappler.com/newsbreak/fact-check/facebook-post-shows-no-real-images-titan-submersible-wreckage/\n",
            "--- --- --- --- ---\n",
            "\n",
            "Generating query from image: 'datasets/extracted_images\\img_2_H4.png'\n",
            "Generating query from text: 'Is Filipino basketball star Kai Sotto the most underrated player Kevin Durant has played with?'\n",
            "Searching with query: 'filipino basketball star kai sotto underrated player kevin durant played'\n",
            "Found 2 URLs\n",
            "MATCH: https://www.rappler.com/newsbreak/fact-check/fact-check-supposed-kevin-durant-tweet-commending-kai-sotto-is-fake/\n",
            "--- --- --- --- ---\n",
            "\n",
            "Generating query from image: 'datasets/extracted_images\\img_3_H5.png'\n",
            "Generating query from text: 'Durant and Sotto never played in an official game together.'\n",
            "Searching with query: 'durant sotto never played official game together'\n",
            "Found 5 URLs\n",
            "MATCH: https://www.rappler.com/newsbreak/fact-check/fact-check-supposed-kevin-durant-tweet-commending-kai-sotto-is-fake/\n",
            "--- --- --- --- ---\n",
            "\n",
            "Generating query from image: 'datasets/extracted_images\\img_4_H6.png'\n",
            "Generating query from text: 'Nakamit ni Ferdinand \"Bongbong\" Marcos Jr. ang unang gantimpala sa Gawad Alab Haraya ng National Commission for Culture and the Arts (NCCA) noong 2002.'\n",
            "Searching with query: 'nakamit ferdinand bongbong marcos ang unang gantimpala gawad alab haraya national commission culture art ncca noong 2002'\n",
            "Found 1 URLs\n",
            "MATCH: https://www.rappler.com/newsbreak/fact-check/ferdinand-bongbong-marcos-jr-awarded-gawad-alab-haraya-ncca/\n",
            "--- --- --- --- ---\n",
            "\n",
            "Generating query from text: 'Ang Museo Ilocos Norte ang nakatanggap ng Gawad Alab Haraya noong 2022, hindi si Bongbong Marcos Jr. '\n",
            "Searching with query: 'ang museo ilocos norte nakatanggap gawad alab haraya noong 2022 hindi bongbong marcos'\n",
            "Found 1 URLs\n",
            "MATCH: https://www.rappler.com/newsbreak/fact-check/ferdinand-bongbong-marcos-jr-awarded-gawad-alab-haraya-ncca/\n",
            "--- --- --- --- ---\n",
            "\n",
            "Generating query from image: 'datasets/extracted_images\\img_5_H8.png'\n",
            "Generating query from text: 'Is the photo of Lionel Messi holding the Israeli flag real?'\n",
            "Searching with query: 'photo lionel messi holding israeli flag real'\n",
            "Found 5 URLs\n",
            "MATCH: https://www.rappler.com/newsbreak/fact-check/altered-photo-lionel-messi-holding-israel-flag/\n",
            "--- --- --- --- ---\n",
            "\n",
            "Generating query from image: 'datasets/extracted_images\\img_6_H9.png'\n",
            "Generating query from text: 'Is the photo showing Messi holding the national flag of Israel digitally altered?'\n",
            "Searching with query: 'photo showing messi holding national flag israel digitally altered'\n",
            "Found 1 URLs\n",
            "MATCH: https://www.rappler.com/newsbreak/fact-check/altered-photo-lionel-messi-holding-israel-flag/\n",
            "--- --- --- --- ---\n",
            "\n",
            "Generating query from image: 'datasets/extracted_images\\img_7_H10.png'\n",
            "Generating query from text: '\"Dr. Augusto Litonjua, a diabetes expert, stated: 'My research and I have found a new approach to reduce complications and control diabetes until today.'\"'\n",
            "Searching with query: 'augusto litonjua diabetes expert stated research found new approach reduce complication control today'\n",
            "Found 3 URLs\n",
            "MATCH: https://www.rappler.com/newsbreak/fact-check/fake-quote-diabetes-expert-promote-glufarelin/\n",
            "--- --- --- --- ---\n",
            "\n",
            "Generating query from text: 'The quote card attributed to Dr. Augusto Litonjua is a recycled version of similar fake posts used to promote the unregistered product Glufarelin, and the Facebook page that posted the claim is not affiliated with the Philippine General Hospital (PGH). '\n",
            "Searching with query: 'quote card attributed augusto litonjua recycled version similar fake post used promote unregistered product glufarelin facebook page posted claim affiliated philippine general hospital pgh'\n",
            "Found 1 URLs\n",
            "MATCH: https://www.rappler.com/newsbreak/fact-check/fake-quote-diabetes-expert-promote-glufarelin/\n",
            "--- --- --- --- ---\n",
            "\n",
            "Generating query from image: 'datasets/extracted_images\\img_8_H12.png'\n",
            "Generating query from text: 'Larawan ng Davao City Bypass Project ang ipinakita sa isang artikulo sa website ng Department of Public Works and Highways (DPWH).'\n",
            "Searching with query: 'larawan davao city bypass project ang ipinakita isang artikulo website department public work highway dpwh'\n",
            "Found 1 URLs\n",
            "MATCH: https://www.rappler.com/newsbreak/fact-check/photo-davao-city-bypass-project-department-public-works-highways-website/\n",
            "--- --- --- --- ---\n",
            "\n",
            "Generating query from text: 'Ang nasa litrato ay ang pinakamahabang tunnel sa Malaysia at hindi ang Davao City Bypass Project.'\n",
            "Searching with query: 'ang nasa litrato pinakamahabang tunnel malaysia hindi davao city bypass project'\n",
            "Found 1 URLs\n",
            "MATCH: https://www.rappler.com/newsbreak/fact-check/photo-davao-city-bypass-project-department-public-works-highways-website/\n",
            "--- --- --- --- ---\n",
            "\n",
            "Generating query from image: 'datasets/extracted_images\\img_9_H14.png'\n",
            "Generating query from text: 'Data from the 1997 Philippine Yearbook released by the National Statistics Office (NSO) shows a summary of government expenditures under former presidents Ferdinand E. Marcos, Corazon Aquino, and Fidel Ramos. \"President Marcos built a massive infrastructure program and had other achievements while succeeding presidents had little to show despite their huge budgets.\"'\n",
            "Searching with query: 'data 1997 philippine yearbook released national statistic office nso show summary government expenditure former president ferdinand marcos corazon aquino fidel ramos built massive infrastructure program achievement succeeding little despite huge budget'\n",
            "Found 2 URLs\n",
            "MATCH: https://www.rappler.com/newsbreak/fact-check/post-shows-incorrect-nso-figures-government-spending-3-former-presidents/\n",
            "--- --- --- --- ---\n",
            "\n",
            "Generating query from image: 'datasets/extracted_images\\img_10_H15.png'\n",
            "Generating query from text: 'The National Statistics Office (NSO), now the Philippine Statistics Authority (PSA), releases annual expenditures, not summaries of government spending by presidency. It is also misleading to compare the peso values without adjusting for inflation.'\n",
            "Searching with query: 'national statistic office nso philippine authority psa release annual expenditure summary government spending presidency also misleading compare peso value without adjusting inflation'\n",
            "Found 2 URLs\n",
            "MATCH: https://www.rappler.com/newsbreak/fact-check/post-shows-incorrect-nso-figures-government-spending-3-former-presidents/\n",
            "--- --- --- --- ---\n",
            "\n",
            "Generating query from image: 'datasets/extracted_images\\img_11_H16.png'\n",
            "Generating query from text: 'A photo of Renato Reyes, Secretary-General of Bagong Alyansang Makabayan (Bayan), shows his alleged attendance at a rally during the term of President Ferdinand Marcos Jr. The photo has a description that says \"Reyes on BBM.\"'\n",
            "Searching with query: 'photo renato reyes secretary general bagong alyansang makabayan bayan show alleged attendance rally term president ferdinand marcos description say bbm'\n",
            "Found 1 URLs\n",
            "MATCH: https://www.rappler.com/newsbreak/fact-check/renato-reyes-photo-described-reyes-bbm-taken-before-marcos-jr-term/\n",
            "--- --- --- --- ---\n",
            "\n",
            "Generating query from text: 'Reyes’ photo with the “Reyes on BBM” description was taken before Marcos became president.'\n",
            "Searching with query: 'reyes photo bbm description taken marcos became president'\n",
            "Found 5 URLs\n",
            "MATCH: https://www.rappler.com/newsbreak/fact-check/renato-reyes-photo-described-reyes-bbm-taken-before-marcos-jr-term/\n",
            "--- --- --- --- ---\n",
            "\n",
            "Generating query from image: 'datasets/extracted_images\\img_12_H18.png'\n",
            "Generating query from text: 'Sandro Marcos, son of presidential aspirant Ferdinand \"Bongbong\" Marcos Jr., claims all the Marcoses running in the 2022 elections will win without campaigning.'\n",
            "Searching with query: 'sandro marcos son presidential aspirant ferdinand bongbong claim marcoses running 2022 election win without campaigning'\n",
            "Found 5 URLs\n",
            "MATCH: https://www.rappler.com/newsbreak/fact-check/sandro-marcos-says-all-family-members-will-win-2022-elections-without-campaigning/\n",
            "--- --- --- --- ---\n",
            "\n",
            "Generating query from text: 'The original post attributed to Sandro Marcos had a disclaimer it was satire.'\n",
            "Searching with query: 'original post attributed sandro marcos disclaimer satire'\n",
            "Found 1 URLs\n",
            "NO MATCH:\n",
            "Original: https://www.rappler.com/newsbreak/fact-check/sandro-marcos-says-all-family-members-will-win-2022-elections-without-campaigning/\n",
            "Retrieved: ['https://verafiles.org/articles/vera-files-fact-check-sandro-marcos-did-not-say-father-clan']\n",
            "--- --- --- --- ---\n",
            "\n",
            "Generating query from image: 'datasets/extracted_images\\img_13_H20.png'\n",
            "Generating query from text: 'Ameera Naser Khalifa, Princess of Saudi Arabia, praised Ferdinand Marcos Jr. for being a visionary leader and expressed hope to meet him. She criticized those who oppose Marcos as the worst citizens in the country.'\n",
            "Searching with query: 'ameera naser khalifa princess saudi arabia praised ferdinand marcos visionary leader expressed hope meet criticized oppose worst citizen country'\n",
            "Found 0 URLs\n",
            "NO MATCH:\n",
            "Original: https://interaksyon.philstar.com/rumor-cop/2022/01/28/209432/saudi-princess-did-not-praise-prexy-bet/\n",
            "Retrieved: []\n",
            "--- --- --- --- ---\n",
            "\n",
            "Generating query from text: 'The quote card attributed to a supposed Saudi Princess is fake.'\n",
            "Searching with query: 'quote card attributed supposed saudi princess fake'\n",
            "Found 4 URLs\n",
            "NO MATCH:\n",
            "Original: https://interaksyon.philstar.com/rumor-cop/2022/01/28/209432/saudi-princess-did-not-praise-prexy-bet/\n",
            "Retrieved: ['https://interaksyon.philstar.com/rumor-cop/2022/05/12/217115/did-queen-elizabeth-congratulate-marcos-for-2022-election-victory/', 'https://verafiles.org/issues-archive/10250/2022/30/page/6', 'https://www.philstar.com/happens/838', 'https://www.philstar.com/happens/578']\n",
            "--- --- --- --- ---\n",
            "\n",
            "Generating query from image: 'datasets/extracted_images\\img_14_H22.png'\n",
            "Generating query from text: 'A former broadcaster shared a daytime picture of a proclamation rally venue on Facebook with a caption claiming it was taken pre-sunrise time. Jay Sonza on Tuesday posted the photo taken outside the Philippine Arena in Santa Maria, Bulacan.'\n",
            "Searching with query: 'former broadcaster shared daytime picture proclamation rally venue facebook caption claiming taken pre sunrise time jay sonza tuesday posted photo outside philippine arena santa maria bulacan'\n",
            "Found 1 URLs\n",
            "MATCH: https://interaksyon.philstar.com/rumor-cop/2022/02/09/210264/jay-sonza-posts-daytime-pic-of-proclamation-rally-venue-with-pre-sunrise-time-as-caption/\n",
            "--- --- --- --- ---\n",
            "\n",
            "Generating query from text: 'Sonza posted the picture on social media at 3:40 a.m. but the sun has not yet risen in Bulacan at that time.'\n",
            "Searching with query: 'sonza posted picture social medium sun yet risen bulacan time'\n",
            "Found 0 URLs\n",
            "NO MATCH:\n",
            "Original: https://interaksyon.philstar.com/rumor-cop/2022/02/09/210264/jay-sonza-posts-daytime-pic-of-proclamation-rally-venue-with-pre-sunrise-time-as-caption/\n",
            "Retrieved: []\n",
            "--- --- --- --- ---\n",
            "\n",
            "Generating query from image: 'datasets/extracted_images\\img_15_H24.png'\n",
            "Generating query from text: 'Chiz Escudero supports VP Leni and Kiko, expecting 5 million of his voters from the 2016 election to also support them on May 9.'\n",
            "Searching with query: 'chiz escudero support leni kiko expecting million voter 2016 election also may'\n",
            "Found 5 URLs\n",
            "MATCH: https://thebaguiochronicle.com/2022/02/15/fact-check-senatorial-candidate-chiz-escudero-formally-endorsed-vp-leni-robredo-factsfirstph/\n",
            "--- --- --- --- ---\n",
            "\n",
            "Generating query from text: 'Senatorial candidate Chiz Escudero refused to exclusively endorse the Bicolana presidential contender.'\n",
            "Searching with query: 'senatorial candidate chiz escudero refused exclusively endorse bicolana presidential contender'\n",
            "Found 5 URLs\n",
            "MATCH: https://thebaguiochronicle.com/2022/02/15/fact-check-senatorial-candidate-chiz-escudero-formally-endorsed-vp-leni-robredo-factsfirstph/\n",
            "--- --- --- --- ---\n",
            "\n",
            "Generating query from image: 'datasets/extracted_images\\img_16_H26.png'\n",
            "Generating query from text: 'photos dated May 22, 2025 show rice sold at a Davao City mall was now selling in the P20 per kilo range, as President-elect Ferdinand \"Bongbong\" Marcos Jr. promised to lower the price of rice'\n",
            "Searching with query: 'photo dated may 2025 show rice sold davao city mall selling p20 per kilo range president elect ferdinand bongbong marcos promised lower price'\n",
            "Found 1 URLs\n",
            "NO MATCH:\n",
            "Original: https://verafiles.org/articles/vera-files-fact-check-2019-photos-of-rice-prices-in-davao-city-mislead\n",
            "Retrieved: ['https://qa.philstar.com/happens/672']\n",
            "--- --- --- --- ---\n",
            "\n",
            "Generating query from text: 'The supposed photos of rice in Davao City are misleading.'\n",
            "Searching with query: 'supposed photo rice davao city misleading'\n",
            "Found 5 URLs\n",
            "NO MATCH:\n",
            "Original: https://verafiles.org/articles/vera-files-fact-check-2019-photos-of-rice-prices-in-davao-city-mislead\n",
            "Retrieved: ['https://verafiles.org/issues-archive/10250/2022/30/', 'https://www.rappler.com/newsbreak/fact-check/rodrigo-duterte-coca-cola-statue-netherlands-ai-generated/', 'https://verafiles.org/section/fact-check', 'https://www.philstar.com/nation/2025/04/05/2433629/2-fake-news-peddlers-charged', 'https://interaksyon.philstar.com/breaking-news/2017/08/09/89973/duterte-vows-to-quit-file-raps-vs-boc-employees-his-children-if-proven-theyre-into-corrupt-deals/']\n",
            "--- --- --- --- ---\n",
            "\n",
            "Generating query from image: 'datasets/extracted_images\\img_17_H28.png'\n",
            "Generating query from text: 'An FB page using Dr. Josephine Rojo's name thanked people for joining this year's celebration of National Low Carb Day, then urged netizens to buy a mixed nuts cereal called \"Super Meal.\"'\n",
            "Searching with query: 'page using josephine rojo name thanked people joining year celebration national low carb day urged netizens buy mixed nut cereal called super meal'\n",
            "Found 1 URLs\n",
            "MATCH: https://verafiles.org/articles/vera-files-fact-check-altered-photos-of-doctor-used-yet-again-to-scam-netizens\n",
            "--- --- --- --- ---\n",
            "\n",
            "Generating query from image: 'datasets/extracted_images\\img_18_H29.png'\n",
            "Generating query from text: 'With manipulated photos, another post on Facebook (FB) is impersonating a Filipino doctor to sell granola mixed nuts that supposedly aid in weight loss.'\n",
            "Searching with query: 'manipulated photo another post facebook impersonating filipino doctor sell granola mixed nut supposedly aid weight loss'\n",
            "Found 2 URLs\n",
            "MATCH: https://verafiles.org/articles/vera-files-fact-check-altered-photos-of-doctor-used-yet-again-to-scam-netizens\n",
            "--- --- --- --- ---\n",
            "\n",
            "Generating query from image: 'datasets/extracted_images\\img_19_H30.png'\n",
            "Generating query from text: 'The Rodrigo Duterte administration held a crisis meeting with his top leaders.'\n",
            "Searching with query: 'rodrigo duterte administration held crisis meeting top leader'\n",
            "Found 5 URLs\n",
            "NO MATCH:\n",
            "Original: https://verafiles.org/articles/vera-files-fact-check-anti-duterte-facebook-page-uses-fake-p\n",
            "Retrieved: ['https://www.rappler.com/newsbreak/in-depth/208309-how-duterte-handles-crisis-controversy-during-presidency/', 'https://www.philstar.com/headlines/2021/04/22/2093027/duterte-skip-asean-summit-coup-hit-myanmar', 'https://www.philstar.com/headlines/2016/12/23/1656227/amlc-hold-emergency-meeting-after-duterte-remarks', 'https://www.philstar.com/headlines/2023/09/08/2294767/southeast-asian-air-force-chiefs-including-philippines-snub-myanmar-meeting', 'https://www.philstar.com/headlines/2018/11/21/1870517/full-text-joint-statement-philippines-and-china']\n",
            "--- --- --- --- ---\n",
            "\n",
            "Generating query from image: 'datasets/extracted_images\\img_20_H31.png'\n",
            "Generating query from text: 'The two photos showing President Rodrigo Duterte speaking to officials are not of a crisis meeting.'\n",
            "Searching with query: 'two photo showing president rodrigo duterte speaking official crisis meeting'\n",
            "Found 5 URLs\n",
            "MATCH: https://verafiles.org/articles/vera-files-fact-check-anti-duterte-facebook-page-uses-fake-p\n",
            "--- --- --- --- ---\n",
            "\n",
            "Generating query from image: 'datasets/extracted_images\\img_21_H32.png'\n",
            "Generating query from text: 'President Benigno Aquino III is connected to Manila Water, one of two water concessionaires in Metro Manila whom President Rodrigo Duterte accused of economic sabotage because their contracts were disadvantageous to the public.'\n",
            "Searching with query: 'president benigno aquino iii connected manila water one two concessionaire metro rodrigo duterte accused economic sabotage contract disadvantageous public'\n",
            "Found 1 URLs\n",
            "MATCH: https://verafiles.org/articles/vera-files-fact-check-aquino-misleadingly-dragged-manila-wat\n",
            "--- --- --- --- ---\n",
            "\n",
            "Generating query from text: 'Ayala Corporation Scandal is misleading the public; the photo of Aquino with the Ayalas has nothing to do with the video it linked nor with the Manila Water issue. The accusation against media being paid was only copied from Duterte’s pronouncement.'\n",
            "Searching with query: 'ayala corporation scandal misleading public photo aquino ayalas nothing video linked manila water issue accusation medium paid copied duterte pronouncement'\n",
            "Found 0 URLs\n",
            "NO MATCH:\n",
            "Original: https://verafiles.org/articles/vera-files-fact-check-aquino-misleadingly-dragged-manila-wat\n",
            "Retrieved: []\n",
            "--- --- --- --- ---\n",
            "\n",
            "Generating query from image: 'datasets/extracted_images\\img_22_H34.png'\n",
            "Generating query from text: 'A Facebook user posted on Nov. 15, 2023, three photos of megamouth sharks that washed ashore and surrounded by residents. The caption states that the rare sharks were seen in Olaer, Apopong in General Santos City. Several netizens thought the supposedly recent shark sightings were \"signs\" related to the 6.8 earthquake that jolted Mindanao, including General Santos and Sarangani.'\n",
            "Searching with query: 'facebook user posted nov 2023 three photo megamouth shark washed ashore surrounded resident caption state rare seen olaer apopong general santos city several netizens thought supposedly recent sighting sign related earthquake jolted mindanao including sarangani'\n",
            "Found 1 URLs\n",
            "MATCH: https://verafiles.org/articles/vera-files-fact-check-circulating-megamouth-shark-photos-are-old-not-related-to-recent-mindanao-quake\n",
            "--- --- --- --- ---\n",
            "\n",
            "Generating query from text: 'The megamouth sharks in the photos were captured in 2014 and 2015 in other Philippine provinces. They are not related to the recent 6.8 magnitude quake that hit parts of Mindanao.'\n",
            "Searching with query: 'megamouth shark photo captured 2014 2015 philippine province related recent magnitude quake hit part mindanao'\n",
            "Found 1 URLs\n",
            "MATCH: https://verafiles.org/articles/vera-files-fact-check-circulating-megamouth-shark-photos-are-old-not-related-to-recent-mindanao-quake\n",
            "--- --- --- --- ---\n",
            "\n",
            "Generating query from image: 'datasets/extracted_images\\img_23_H36.png'\n",
            "Generating query from text: 'Facebook page Philippine Shocking History posted a before-and-after collage of a Manila estuary to show that the Duterte administration is better than the previous Aquino administration.'\n",
            "Searching with query: 'facebook page philippine shocking history posted collage manila estuary show duterte administration better previous aquino'\n",
            "Found 1 URLs\n",
            "MATCH: https://verafiles.org/articles/vera-files-fact-check-facebook-post-uses-fake-photos-prop-du\n",
            "--- --- --- --- ---\n",
            "\n",
            "Generating query from image: 'datasets/extracted_images\\img_24_H37.png'\n",
            "Generating query from text: 'Facebook page Philippine Shocking History posted a manipulated before-and-after photo collage showing a river filled with trash before and after an intervention by the Pasig River Rehabilitation Commission.'\n",
            "Searching with query: 'facebook page philippine shocking history posted manipulated photo collage showing river filled trash intervention pasig rehabilitation commission'\n",
            "Found 2 URLs\n",
            "MATCH: https://verafiles.org/articles/vera-files-fact-check-facebook-post-uses-fake-photos-prop-du\n",
            "--- --- --- --- ---\n",
            "\n",
            "Generating query from image: 'datasets/extracted_images\\img_25_H38.png'\n",
            "Generating query from text: '\"Who said: 'I would prefer to fail with honor than win by cheating'?\"'\n",
            "Searching with query: 'said would prefer fail honor win cheating'\n",
            "Found 5 URLs\n",
            "MATCH: https://verafiles.org/articles/vera-files-fact-check-fb-page-alters-manila-bulletin-infogra\n",
            "--- --- --- --- ---\n",
            "\n",
            "Generating query from image: 'datasets/extracted_images\\img_26_H39.png'\n",
            "Generating query from text: 'A pro-Marcos Facebook (FB) page posted a doctored 2018 Manila Bulletin quote card featuring former Sen. Ferdinand \"Bongbong\" Marcos Jr. This is fake.'\n",
            "Searching with query: 'pro marcos facebook page posted doctored 2018 manila bulletin quote card featuring former sen ferdinand bongbong fake'\n",
            "Found 2 URLs\n",
            "MATCH: https://verafiles.org/articles/vera-files-fact-check-fb-page-alters-manila-bulletin-infogra\n",
            "--- --- --- --- ---\n",
            "\n",
            "Generating query from image: 'datasets/extracted_images\\img_27_H40.png'\n",
            "Generating query from text: 'While the number of casualties in the deadly earthquake that struck parts of Turkey and Syria continues to rise, so are photos allegedly showing the devastation popping up.'\n",
            "Searching with query: 'number casualty deadly earthquake struck part turkey syria continues rise photo allegedly showing devastation popping'\n",
            "Found 5 URLs\n",
            "MATCH: https://verafiles.org/articles/vera-files-fact-check-fb-pages-circulate-old-photos-not-related-to-killer-quake-in-turkey-and-syria\n",
            "--- --- --- --- ---\n",
            "\n",
            "Generating query from text: 'Images circulating in several Filipino Facebook (FB) pages are unrelated to the tragedy.'\n",
            "Searching with query: 'image circulating several filipino facebook page unrelated tragedy'\n",
            "Found 5 URLs\n",
            "NO MATCH:\n",
            "Original: https://verafiles.org/articles/vera-files-fact-check-fb-pages-circulate-old-photos-not-related-to-killer-quake-in-turkey-and-syria\n",
            "Retrieved: ['https://verafiles.org/topic/earthquake/page/3', 'https://verafiles.org/articles/article-keyword/earthquake', 'https://www.rappler.com/newsbreak/fact-check/newscast-possible-diseases-causedco-covid-19-vaccine-ai-generated/', 'https://verafiles.org/articles/vera-files-fact-check-take-2-for-aircon-sale-scam-with-altered-image-bogus-links', 'https://www.rappler.com/newsbreak/fact-check/raffy-tulfo-advertisement-joint-pain-cure-ai-manipulated/']\n",
            "--- --- --- --- ---\n",
            "\n",
            "Generating query from image: 'datasets/extracted_images\\img_28_H42.png'\n",
            "Generating query from text: 'This is the BIGGEST ANTI SOGIE BILL RALLY in the World.'\n",
            "Searching with query: 'biggest anti sogie bill rally world'\n",
            "Found 5 URLs\n",
            "MATCH: https://verafiles.org/articles/vera-files-fact-check-fb-post-worlds-biggest-anti-sogie-bill\n",
            "--- --- --- --- ---\n",
            "\n",
            "Generating query from text: 'A Sept. 5, 2019 Facebook (FB) post carrying a photo of what it claims to be the world’s biggest protest on the Sexual Orientation, Gender Identity and Expression (SOGIE) Equality bill is not accurate.'\n",
            "Searching with query: 'sept 2019 facebook post carrying photo claim world biggest protest sexual orientation gender identity expression sogie equality bill accurate'\n",
            "Found 1 URLs\n",
            "MATCH: https://verafiles.org/articles/vera-files-fact-check-fb-post-worlds-biggest-anti-sogie-bill\n",
            "--- --- --- --- ---\n",
            "\n",
            "Generating query from image: 'datasets/extracted_images\\img_29_H44.png'\n",
            "Generating query from text: 'A Facebook page posted satellite images of the supertyphoon \"Hagibis.\"'\n",
            "Searching with query: 'facebook page posted satellite image supertyphoon hagibis'\n",
            "Found 1 URLs\n",
            "NO MATCH:\n",
            "Original: https://www.factrakers.org/post/fb-page-shares-wrong-photos-of-hagibis\n",
            "Retrieved: ['https://www.rappler.com/philippines/weather/typhoon-paolo-forecast-track-wind-signals-rain-damage-relief-updates-october-2025/']\n",
            "--- --- --- --- ---\n",
            "\n",
            "Generating query from text: 'A Facebook  page shared wrong photos of what it claimed to be satellite images of supertyphoon \"Hagibis.\"'\n",
            "Searching with query: 'facebook page shared wrong photo claimed satellite image supertyphoon hagibis'\n",
            "Found 0 URLs\n",
            "NO MATCH:\n",
            "Original: https://www.factrakers.org/post/fb-page-shares-wrong-photos-of-hagibis\n",
            "Retrieved: []\n",
            "--- --- --- --- ---\n",
            "\n",
            "Generating query from image: 'datasets/extracted_images\\img_30_H46.png'\n",
            "Generating query from text: 'Photos show protestors rallying in front of Hacienda Luisita in Tarlac, Philippines.'\n",
            "Searching with query: 'photo show protestors rallying front hacienda luisita tarlac philippine'\n",
            "Found 5 URLs\n",
            "NO MATCH:\n",
            "Original: https://www.factrakers.org/post/website-posts-manipulated-image-of-hacienda-luisita-rally\n",
            "Retrieved: ['https://www.rappler.com/newsbreak/iq/149884-look-back-philippine-protests-bloody/', 'https://www.rappler.com/philippines/113636-hacienda-luisita-land-reform-florida-sibayan/', 'https://interaksyon.philstar.com/breaking-news/2017/07/24/86438/expect-fiery-sona-protests-as-poverty-remains-pervasive-amid-du30-war-on-drugs-terror/', 'https://www.philstar.com/headlines/2016/12/13/1653012/psg-serenades-rody-tarlacs-christmas-event', 'https://www.rappler.com/environment/why-southern-palawan-indigenous-people-hunger-strike/']\n",
            "--- --- --- --- ---\n",
            "\n",
            "Generating query from text: 'A website posted a doctored image of protestors supposedly rallying in front of Hacienda Luisita in  Tarlac.'\n",
            "Searching with query: 'website posted doctored image protestors supposedly rallying front hacienda luisita tarlac'\n",
            "Found 1 URLs\n",
            "NO MATCH:\n",
            "Original: https://www.factrakers.org/post/website-posts-manipulated-image-of-hacienda-luisita-rally\n",
            "Retrieved: ['https://verafiles.org/wp-content/uploads/docs/2008-impeachment-complaint.pdf']\n",
            "--- --- --- --- ---\n",
            "\n",
            "Generating query from image: 'datasets/extracted_images\\img_31_H48.png'\n",
            "Generating query from text: 'The Philippines still has a Fake Vice-President (VP) Leni Robredo. The fake Philippine VP is also a whore.'\n",
            "Searching with query: 'philippine still fake vice president leni robredo also whore'\n",
            "Found 5 URLs\n",
            "NO MATCH:\n",
            "Original: https://www.factrakers.org/post/image-of-cnn-report-altered-to-label-robredo-fake-vp\n",
            "Retrieved: ['https://www.rappler.com/philippines/elections/female-candidates-leni-robredo-sara-duterte-face-gendered-attacks-online-misogyny/', 'https://verafiles.org/articles/vera-files-fact-check-no-world-didnt-look-duterte-cursing-ob', 'https://www.rappler.com/technology/features/women-leaders-criticizing-government-consequences-price-attacks/', 'https://www.rappler.com/features/newsbreak/in-depth/217563-disinformation-gone-macho/index.html', 'https://www.rappler.com/voices/thought-leaders/opinion-post-mortem-comparisons-macronleaks-vs-nagaleaks/']\n",
            "--- --- --- --- ---\n",
            "\n",
            "Generating query from image: 'datasets/extracted_images\\img_32_H49.png'\n",
            "Generating query from text: 'A Facebook page posted a doctored image of a CNN news segment saying Vice President Maria Leonor \"Leni\" Robredo is a \"fake\" vice president and calling her a \"whore.\"'\n",
            "Searching with query: 'facebook page posted doctored image cnn news segment saying vice president maria leonor leni robredo fake calling whore'\n",
            "Found 0 URLs\n",
            "NO MATCH:\n",
            "Original: https://www.factrakers.org/post/image-of-cnn-report-altered-to-label-robredo-fake-vp\n",
            "Retrieved: []\n",
            "--- --- --- --- ---\n",
            "\n",
            "Generating query from image: 'datasets/extracted_images\\img_33_H50.png'\n",
            "Generating query from text: 'A picture of former Vice President Leni Robredo with bloodshot eyes quotes her: HINTAYIN NYO AKO MAGING PRESIDENTE GAGAWIN KONG LEGAL ANG SHABU (Wait until I become president, I will make shabu legal.)'\n",
            "Searching with query: 'picture former vice president leni robredo bloodshot eye quote hintayin nyo ako maging presidente gagawin kong legal ang shabu wait become make'\n",
            "Found 0 URLs\n",
            "NO MATCH:\n",
            "Original: https://www.factrakers.org/post/netizen-posts-manipulated-photo-of-robredo-with-bloodshot-eyes\n",
            "Retrieved: []\n",
            "--- --- --- --- ---\n",
            "\n",
            "Generating query from image: 'datasets/extracted_images\\img_34_H51.png'\n",
            "Generating query from text: 'A Facebook user posted a manipulated photo showing Vice President Maria Leonor \"Leni\" Robredo with bloodshot eyes.'\n",
            "Searching with query: 'facebook user posted manipulated photo showing vice president maria leonor leni robredo bloodshot eye'\n",
            "Found 5 URLs\n",
            "MATCH: https://www.factrakers.org/post/netizen-posts-manipulated-photo-of-robredo-with-bloodshot-eyes\n",
            "--- --- --- --- ---\n",
            "\n",
            "\n",
            "Dataset processing complete.\n"
          ]
        }
      ],
      "source": [
        "input_df = get_df(\"datasets/sheets/Patunai-IR-image-augemented-dataset.xlsx\")\n",
        "output_df = process_dataset(pipeline, input_df)\n",
        "print(\"\\nDataset processing complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_df.to_excel(\"datasets/output/retrieval_only_image_caption.xlsx\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Retrieval Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_match_score(df: pd.DataFrame):\n",
        "    if \"Match\" not in df.columns:\n",
        "        raise ValueError(\"DataFrame must contain a 'Match' column.\")\n",
        "\n",
        "    valid_matches = df[\"Match\"].dropna()\n",
        "\n",
        "    if len(valid_matches) == 0:\n",
        "        print(\"No valid matches found in dataset.\")\n",
        "        return 0.0\n",
        "\n",
        "    score = valid_matches.mean()\n",
        "    print(f\"Retrieval accuracy: {score:.2%} ({valid_matches.sum()}/{len(valid_matches)} correct)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieval accuracy: 68.00% (34/50 correct)\n"
          ]
        }
      ],
      "source": [
        "show_match_score(output_df)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "patunai-ir",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
